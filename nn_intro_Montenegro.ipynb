{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LAB 3\n",
        "- Edwin Montenegro\n",
        "- Galo Travez"
      ],
      "metadata": {
        "id": "k09l8bv_3MZH"
      },
      "id": "k09l8bv_3MZH"
    },
    {
      "cell_type": "markdown",
      "id": "e2c88e42-50d4-4b4d-bdf1-894bcff1a41d",
      "metadata": {
        "id": "e2c88e42-50d4-4b4d-bdf1-894bcff1a41d"
      },
      "source": [
        "# NLP and Neural Networks\n",
        "\n",
        "In this exercise, we'll apply our knowledge of neural networks to process natural language. As we did in the bigram exercise, the goal of this lab is to predict the next word, given the previous one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5132d376-54d7-48c3-a52c-ac3d94ed798b",
      "metadata": {
        "id": "5132d376-54d7-48c3-a52c-ac3d94ed798b"
      },
      "source": [
        "### Data set\n",
        "\n",
        "Load the text from \"One Hundred Years of Solitude\" that we used in our bigrams exercise. It's located in the data folder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoMF6lkbEoi0",
        "outputId": "728a63a8-b483-4d12-c643-b5f4182769e0"
      },
      "id": "EoMF6lkbEoi0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('/content/drive/MyDrive/TALLERES NLP /cap_1_first_10.txt', 'r').read().lower()"
      ],
      "metadata": {
        "id": "UGDFWQPkEs--"
      },
      "id": "UGDFWQPkEs--",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9e309d79-7746-40e3-8a02-3cc7b45c16ac",
      "metadata": {
        "id": "9e309d79-7746-40e3-8a02-3cc7b45c16ac"
      },
      "source": [
        "### Important note:\n",
        "\n",
        "Start with a smaller part of the text. Maybe the first 10 parragraphs, as the number of tokens rapidly increases as we add more text.\n",
        "\n",
        "Later you can use a bigger corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9bbced32-a252-48b0-bc8f-cecfdcf1ec2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "9bbced32-a252-48b0-bc8f-cecfdcf1ec2e",
        "outputId": "7a6487fa-3732-4e7c-cda7-d8beea297a4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'muchos años después, frente al pelotón de fusilamiento, el coronel aureliano buendía había de recordar aquella tarde remota en que su padre lo llevó a conocer el hielo. macondo era entonces una aldea de veinte casas de barro y cañabrava construidas a la orilla de un río de aguas diáfanas que se precipitaban por un lecho de piedras pulidas, blancas y enormes como huevos prehistóricos. el mundo era tan reciente, que muchas cosas carecían de nombre, y para mencionarlas había que señalarlas con el dedo. todos los años, por el mes de marzo, una familia de gitanos desarrapados plantaba su carpa cerca de la aldea, y con un grande alboroto de pitos y timbales daban a conocer los nuevos inventos. primero llevaron el imán. un gitano corpulento, de barba montaraz y manos de gorrión, que se presentó con el nombre de melquíades, hizo una truculenta demostración pública de lo que él mismo llamaba la octava maravilla de los sabios alquimistas de macedonia. fue de casa en casa arrastrando dos lingotes metálicos, y todo el mundo se espantó al ver que los calderos, las pailas, las tenazas y los anafes se caían de su sitio, y las maderas crujían por la desesperación de los clavos y los tornillos tratando de desenclavarse, y aun los objetos perdidos desde hacía mucho tiempo aparecían por donde más se les había buscado, y se arrastraban en desbandada turbulenta detrás de los fierros mágicos de melquíades. «las cosas tienen vida propia —pregonaba el gitano con áspero acento—, todo es cuestión de despertarles el ánima.» josé arcadio buendía, cuya desaforada imaginación iba siempre más lejos que el ingenio de la naturaleza, y aun más allá del milagro y la magia, pensó que era posible servirse de aquella invención inútil para desentrañar el oro de la tierra. melquíades, que era un hombre honrado, le previno: «para eso no sirve.» pero josé arcadio buendía no creía en aquel tiempo en la honradez de los gitanos, así que cambió su mulo y una partida de chivos por los dos lingotes imantados. úrsula iguarán, su mujer, que contaba con aquellos animales para ensanchar el desmedrado patrimonio doméstico, no consiguió disuadirlo. «muy pronto ha de sobrarnos oro para empedrar la casa», replicó su marido. durante varios meses se empeñó en demostrar el acierto de sus conjeturas. exploró palmo a palmo la región, inclusive el fondo del río, arrastrando los dos lingotes de hierro y recitando en voz alta el conjuro de melquíades. lo único que logró desenterrar fue una armadura del siglo xv con todas sus partes soldadas por un cascote de óxido, cuyo interior tenía la resonancia hueca de un enorme calabazo lleno de piedras. cuando josé arcadio buendía y los cuatro hombres de su expedición lograron desarticular la armadura, encontraron dentro un esqueleto calcificado que llevaba colgado en el cuello un relicario de cobre con un rizo de mujer.\\n \\nen marzo volvieron los gitanos. esta vez llevaban un catalejo y una lupa del tamaño de un tambor, que exhibieron como el último descubrimiento de los judíos de amsterdam. sentaron una gitana en un extremo de la aldea e instalaron el catalejo a la entrada de la carpa. mediante el pago de cinco reales, la gente se asomaba al catalejo y veía a la gitana al alcance de su mano. «la ciencia ha eliminado las distancias», pregonaba melquíades. «dentro de poco, el hombre podrá ver lo que ocurre en cualquier lugar de la tierra, sin moverse de su casa.» un mediodía ardiente hicieron una asombrosa demostración con la lupa gigantesca: pusieron un montón de hierba seca en mitad de la calle y le prendieron fuego mediante la concentración de los rayos solares. josé arcadio buendía, que aún no acababa de consolarse por el fracaso de sus imanes, concibió la idea de utilizar aquel invento como un arma de guerra. melquíades, otra vez, trató de disuadirlo. pero terminó por aceptar los dos lingotes imantados y tres piezas de dinero colonial a cambio de la lupa. úrsula lloró de consternación. aquel dinero formaba parte de un cofre de monedas de oro que su padre había acumulado en toda una vida de privaciones, y que ella había enterrado debajo de la cama en espera de una buena ocasión para invertirlas. josé arcadio buendía no trató siquiera de consolarla, entregado por entero a sus experimentos tácticos con la abnegación de un científico y aun a riesgo de su propia vida. tratando de demostrar los efectos de la lupa en la tropa enemiga, se expuso él mismo a la concentración de los rayos solares y sufrió quemaduras que se convirtieron en úlceras y tardaron mucho tiempo en sanar. ante las protestas de su mujer, alarmada por tan peligrosa inventiva, estuvo a punto de incendiar la casa. pasaba largas horas en su cuarto, haciendo cálculos sobre las posibilidades estratégicas de su arma novedosa, hasta que logró componer un manual de una asombrosa claridad didáctica y un poder de convicción irresistible. lo envió a las autoridades acompañado de numerosos testimonios sobre sus experiencias y de varios pliegos de dibujos explicativos, al cuidado de un mensajero que atravesó la sierra, se extravió en pantanos desmesurados, remontó ríos tormentosos y estuvo a punto de perecer bajo el azote de las fieras, la desesperación y la peste, antes de conseguir una ruta de enlace con las mulas del correo. a pesar de que el viaje a la capital era en aquel tiempo poco menos que imposible, josé arcadio buendía prometía intentarlo tan pronto como se lo ordenara el gobierno, con el fin de hacer demostraciones prácticas de su invento ante los poderes militares, y adiestrarlos personalmente en las complicadas artes de la guerra solar. durante varios años esperó la respuesta. por último, cansado de esperar, se lamentó ante melquíades del fracaso de su iniciativa, y el gitano dio entonces una prueba convincente de honradez: le devolvió los doblones a cambio de la lupa, y le dejó además unos mapas portugueses y varios instrumentos de navegación. de su puño y letra escribió una apretada síntesis de los estudios del monje hermann, que dejó a su disposición para que pudiera servirse del astrolabio, la brújula y el sextante. josé arcadio buendía pasó los largos meses de lluvia encerrado en un cuartito que construyó en el fondo de la casa para que nadie perturbara sus experimentos. habiendo abandonado por completo las obligaciones domésticas, permaneció noches enteras en el patio vigilando el curso de los astros, y estuvo a punto de contraer una insolación por tratar de establecer un método exacto para encontrar el mediodía. cuando se hizo experto en el uso y manejo de sus instrumentos, tuvo una noción del espacio que le permitió navegar por mares incógnitos, visitar territorios deshabitados y trabar relación con seres espléndidos, sin necesidad de abandonar su gabinete. fue esa la época en que adquirió el hábito de hablar a solas, paseándose por la casa sin hacer caso de nadie, mientras úrsula y los niños se partían el espinazo en la huerta cuidando el plátano y la malanga, la yuca y el ñame, la ahuyama y la berenjena. de pronto, sin ningún anuncio, su actividad febril se interrumpió y fue sustituida por una especie de fascinación. estuvo varios días como hechizado, repitiéndose a sí mismo en voz baja un sartal de asombrosas conjeturas, sin dar crédito a su propio entendimiento. por fin, un martes de diciembre, a la hora del almuerzo, soltó de un golpe toda la carga de su tormento. los niños habían de recordar por el resto de su vida la augusta solemnidad con que su padre se sentó a la cabecera de la mesa, temblando de fiebre, devastado por la prolongada vigilia y por el encono de su imaginación, y les reveló su descubrimiento:\\n \\n—la tierra es redonda como una naranja.\\n \\núrsula perdió la paciencia. «si has de volverte loco, vuélvete tú solo», gritó. «pero no trates de inculcar a los niños tus ideas de gitano.» josé arcadio buendía, impasible, no se dejó amedrentar por la desesperación de su mujer, que en un rapto de cólera le destrozó el astrolabio contra el suelo. construyó otro, reunió en el cuartito a los hombres del pueblo y les demostró, con teorías que para todos resultaban incomprensibles, la posibilidad de regresar al punto de partida navegando siempre hacia el oriente. toda la aldea estaba convencida de que josé arcadio buendía había perdido el juicio, cuando llegó melquíades a poner las cosas en su punto. exaltó en público la inteligencia de aquel hombre que por pura especulación astronómica había construido una teoría ya comprobada en la práctica, aunque desconocida hasta entonces en macondo, y como una prueba de su admiración le hizo un regalo que había de ejercer una influencia terminante en el futuro de la aldea: un laboratorio de alquimia.\\n \\npara esa época, melquíades había envejecido con una rapidez asombrosa. en sus primeros viajes parecía tener la misma edad de josé arcadio buendía. pero mientras éste conservaba su fuerza descomunal, que le permitía derribar un caballo agarrándolo por las orejas, el gitano parecía estragado por una dolencia tenaz. era, en realidad, el resultado de múltiples y raras enfermedades contraídas en sus incontables viajes alrededor del mundo. según él mismo le contó a josé arcadio buendía mientras lo ayudaba a montar el laboratorio, la muerte lo seguía a todas partes, husmeándole los pantalones, pero sin decidirse a darle el zarpazo final. era un fugitivo de cuantas plagas y catástrofes habían flagelado al género humano. sobrevivió a la pelagra en persia, al escorbuto en el archipiélago de malasia, a la lepra en alejandría, al beriberi en el japón, a la peste bubónica en madagascar, al terremoto de sicilia y a un naufragio multitudinario en el estrecho de magallanes. aquel ser prodigioso que decía poseer las claves de nostradamus, era un hombre lúgubre, envuelto en un aura triste, con una mirada asiática que parecía conocer el otro lado de las cosas. usaba un sombrero grande y negro, como las alas extendidas de un cuervo, y un chaleco de terciopelo patinado por el verdín de los siglos. pero a pesar de su inmensa sabiduría y de su ámbito misterioso tenía un peso humano, una condición terrestre que lo mantenía enredado en los minúsculos problemas de la vida cotidiana. se quejaba de dolencias de viejo, sufría por los más insignificantes percances económicos y había dejado de reír desde hacía mucho tiempo, porque el escorbuto le había arrancado los dientes. el sofocante mediodía en que reveló sus secretos, josé arcadio buendía tuvo la certidumbre de que aquel era el principio de una grande amistad. los niños se asombraron con sus relatos fantásticos. aureliano, que no tenía entonces más de cinco años, había de recordarlo por el resto de su vida como lo vio aquella tarde, sentado contra la claridad metálica y reverberante de la ventana, alumbrando con su profunda voz de órgano los territorios más oscuros de la imaginación, mientras chorreaba por sus sienes la grasa derretida por el calor. josé arcadio, su hermano mayor, había de transmitir aquella imagen maravillosa, como un recuerdo hereditario, a toda su descendencia. úrsula, en cambio, conservó un mal recuerdo de aquella visita, porque entró al cuarto en el momento en que melquíades rompió por distracción un frasco de bicloruro de mercurio.\\n\\n—es el olor del demonio —dijo ella.\\n—en absoluto —corrigió melquíades—. está comprobado que el demonio tiene propiedades sulfúricas, y esto no es más que un poco de solimán.\\n \\n\\nsiempre didáctico, hizo una sabia exposición sobre las virtudes diabólicas del cinabrio, pero úrsula no le hizo caso, sino que se llevó los niños a rezar. aquel olor mordiente quedaría para siempre en su memoria, vinculado al recuerdo de melquíades.\\n \\n\\nel rudimentario laboratorio —sin contar una profusión de cazuelas, embudos, retortas, filtros y coladores— estaba compuesto por un atanor primitivo; una probeta de cristal de cuello largo y angosto, imitación del huevo filosófico, y un destilador construido por los propios gitanos según las descripciones modernas del alambique de tres brazos de maría la judía. además de estas cosas, melquíades dejó muestras de los siete metales correspondientes a los siete planetas, las fórmulas de moisés y zósimo para el doblado del oro, y una serie de apuntes y dibujos sobre los procesos del gran magisterio, que permitían a quien supiera interpretarlos intentar la fabricación de la piedra filosofal. seducido por la simplicidad de las fórmulas para doblar el oro, josé arcadio buendía cortejó a úrsula durante varias semanas, para que le permitiera desenterrar sus monedas coloniales y aumentarlas tantas veces como era posible subdividir el azogue. úrsula cedió, como ocurría siempre, ante la inquebrantable obstinación de su marido. entonces josé arcadio buendía echó treinta doblones en una cazuela, y los fundió con raspadura de cobre, oropimente, azufre y plomo. puso a hervir todo a fuego vivo en un caldero de aceite de ricino hasta obtener un jarabe espeso y pestilente más parecido al caramelo vulgar que al oro magnífico. en azarosos y desesperados procesos de destilación, fundida con los siete metales planetarios, trabajada con el mercurio hermético y el vitriolo de chipre, y vuelta a cocer en manteca de cerdo a falta de aceite de rábano, la preciosa herencia de úrsula quedó reducida a un chicharrón carbonizado que no pudo ser desprendido del fondo del caldero.\\n \\n\\ncuando volvieron los gitanos, úrsula había predispuesto contra ellos a toda la población. pero la curiosidad pudo más que el temor, porque aquella vez los gitanos recorrieron la aldea haciendo un ruido ensordecedor con toda clase de instrumentos músicos, mientras el pregonero anunciaba la exhibición del más fabuloso hallazgo de los nasciancenos. de modo que todo el mundo se fue a la carpa, y mediante el pago de un centavo vieron un melquíades juvenil, repuesto, desarrugado, con una dentadura nueva y radiante. quienes recordaban sus encías destruidas por el escorbuto, sus mejillas fláccidas y sus labios marchitos se estremecieron de pavor ante aquella prueba terminante de los poderes sobrenaturales del gitano. el pavor se convirtió en pánico cuando melquíades se sacó los dientes, intactos, engastados en las encías, y se los mostró al público por un instante —un instante fugaz en que volvió a ser el mismo hombre decrépito de los años anteriores— y se los puso otra vez y sonrió de nuevo con un dominio pleno de su juventud restaurada. hasta el propio josé arcadio buendía consideró que los conocimientos de melquíades habían llegado a extremos intolerables, pero experimentó un saludable alborozo cuando el gitano le explicó a solas el mecanismo de su dentadura postiza. aquello le pareció a la vez tan sencillo y prodigioso, que de la noche a la mañana perdió todo interés en las investigaciones de alquimia; sufrió una nueva crisis de mal humor, no volvió a comer en forma regular y se pasaba el día dando vueltas por la casa. «en el mundo están ocurriendo cosas increíbles», le decía a úrsula. «ahí mismo, al otro lado del río, hay toda clase de aparatos mágicos, mientras nosotros seguimos viviendo como los burros.» quienes lo conocían desde los tiempos de la fundación de macondo se asombraban de cuánto había cambiado bajo la influencia de melquíades.\\n \\n\\nal principio, josé arcadio buendía era una especie de patriarca juvenil, que daba instrucciones para la siembra y consejos para la crianza de niños y animales, y colaboraba con todos, aun en el trabajo físico, para la buena marcha de la comunidad. puesto que su casa fue desde el primer momento la mejor de la aldea, las otras fueron arregladas a su imagen y semejanza. tenía una salita amplia y bien iluminada, un comedor en forma de terraza con flores de colores alegres, dos dormitorios, un patio con un castaño gigantesco, un huerto bien plantado y un corral donde vivían en comunidad pacífica los chivos, los cerdos y las gallinas. los únicos animales prohibidos no sólo en la casa, sino en todo el poblado, eran los gallos de pelea.\\n \\n\\nla laboriosidad de úrsula andaba a la par con la de su marido. activa, menuda, severa, aquella mujer de nervios inquebrantables, a quien en ningún momento de su vida se la oyó cantar, parecía estar en todas partes desde el amanecer hasta muy entrada la noche, siempre perseguida por el suave susurro de sus pollerines de olán. gracias a ella, los pisos de tierra golpeada, los muros de barro sin encalar, los rústicos muebles de madera construidos por ellos mismos estaban siempre limpios, y los viejos arcones donde se guardaba la ropa exhalaban un tibio olor de albahaca.\\n \\n\\njosé arcadio buendía, que era el hombre más emprendedor que se vería jamás en la aldea, había dispuesto de tal modo la posición de las casas, que desde todas podía llegarse al río y abastecerse de agua con igual esfuerzo, y trazó las calles con tan buen sentido que ninguna casa recibía más sol que otra a la hora del calor. en pocos años, macondo fue una aldea más ordenada y laboriosa que cualquiera de las conocidas hasta entonces por sus 300 habitantes. era en verdad una aldea feliz, donde nadie era mayor de treinta años y donde nadie había muerto.\\n \\n\\ndesde los tiempos de la fundación, josé arcadio buendía construyó trampas y jaulas. en poco tiempo llenó de turpiales, canarios, azulejos y petirrojos no sólo la propia casa, sino todas las de la aldea. el concierto de tantos pájaros distintos llegó a ser tan aturdidor, que úrsula se tapó los oídos con cera de abejas para no perder el sentido de la realidad. la primera vez que llegó la tribu de melquíades vendiendo bolas de vidrio para el dolor de cabeza, todo el mundo se sorprendió de que hubieran podido encontrar aquella aldea perdida en el sopor de la ciénaga, y los gitanos confesaron que se habían orientado por el canto de los pájaros.\\n \\n\\naquel espíritu de iniciativa social desapareció en poco tiempo, arrastrado por la fiebre de los imanes, los cálculos astronómicos, los sueños de transmutación y las ansias de conocer las maravillas del mundo. de emprendedor y limpio, josé arcadio buendía se convirtió en un hombre de aspecto holgazán, descuidado en el vestir, con una barba salvaje que úrsula lograba cuadrar a duras penas con un cuchillo de cocina. no faltó quien lo considerara víctima de algún extraño sortilegio. pero hasta los más convencidos de su locura abandonaron trabajo y familias para seguirlo, cuando se echó al hombro sus herramientas de desmontar, y pidió el concurso de todos para abrir una trocha que pusiera a macondo en contacto con los grandes inventos.\\n \\n\\njosé arcadio buendía ignoraba por completo la geografía de la región. sabía que hacia el oriente estaba la sierra impenetrable, y al otro lado de la sierra la antigua ciudad de riohacha, donde en épocas pasadas —según le había contado el primer aureliano buendía, su abuelo— sir francis drake se daba al deporte de cazar caimanes a cañonazos, que luego hacía remendar y rellenar de paja para llevárselos a la reina isabel. en su juventud, él y sus hombres, con mujeres y niños y animales y toda clase de enseres domésticos, atravesaron la sierra buscando una salida al mar, y al cabo de veintiséis meses desistieron de la empresa y fundaron a macondo para no tener que emprender el camino de regreso. era, pues, una ruta que no le interesaba, porque sólo podía conducirlo al pasado. al sur estaban los pantanos, cubiertos de una eterna nata vegetal, y el vasto universo de la ciénaga grande, que según testimonio de los gitanos carecía de límites. la ciénaga grande se confundía al occidente con una extensión acuática sin horizontes, donde había cetáceos de piel delicada con cabeza y torso de mujer, que perdían a los navegantes con el hechizo de sus tetas descomunales. los gitanos navegaban seis meses por esa ruta antes de alcanzar el cinturón de tierra firme por donde pasaban las mulas del correo. de acuerdo con los cálculos de josé arcadio buendía, la única posibilidad de contacto con la civilización era la ruta del norte. de modo que dotó de herramientas de desmonte y armas de cacería a los mismos hombres que lo acompañaron en la fundación de macondo; echó en una mochila sus instrumentos de orientación y sus mapas, y emprendió la temeraria aventura.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1393d6-7cbf-4e8e-a699-0f0cd28982a3",
      "metadata": {
        "id": "3d1393d6-7cbf-4e8e-a699-0f0cd28982a3"
      },
      "source": [
        "Don't forget to prepare the data by generating the corresponding tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9c33da77-ad0b-4eeb-9eaa-0dc98485187f",
      "metadata": {
        "id": "9c33da77-ad0b-4eeb-9eaa-0dc98485187f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "t7oeEh-rHvxW"
      },
      "id": "t7oeEh-rHvxW",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xHDW2hyH5Fy",
        "outputId": "8572faf3-125a-4fef-a7b7-14197b3c8988"
      },
      "id": "3xHDW2hyH5Fy",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muchos',\n",
              " 'años',\n",
              " 'después',\n",
              " ',',\n",
              " 'frente',\n",
              " 'al',\n",
              " 'pelotón',\n",
              " 'de',\n",
              " 'fusilamiento',\n",
              " ',',\n",
              " 'el',\n",
              " 'coronel',\n",
              " 'aureliano',\n",
              " 'buendía',\n",
              " 'había',\n",
              " 'de',\n",
              " 'recordar',\n",
              " 'aquella',\n",
              " 'tarde',\n",
              " 'remota',\n",
              " 'en',\n",
              " 'que',\n",
              " 'su',\n",
              " 'padre',\n",
              " 'lo',\n",
              " 'llevó',\n",
              " 'a',\n",
              " 'conocer',\n",
              " 'el',\n",
              " 'hielo.',\n",
              " 'macondo',\n",
              " 'era',\n",
              " 'entonces',\n",
              " 'una',\n",
              " 'aldea',\n",
              " 'de',\n",
              " 'veinte',\n",
              " 'casas',\n",
              " 'de',\n",
              " 'barro',\n",
              " 'y',\n",
              " 'cañabrava',\n",
              " 'construidas',\n",
              " 'a',\n",
              " 'la',\n",
              " 'orilla',\n",
              " 'de',\n",
              " 'un',\n",
              " 'río',\n",
              " 'de']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7681843a-18f0-4d7c-9b02-83015f4383e1",
      "metadata": {
        "id": "7681843a-18f0-4d7c-9b02-83015f4383e1"
      },
      "source": [
        "### Let's prepare the data set.\n",
        "\n",
        "Our neural network needs to have an input X and an output y. Remember that these sets are numerical, so you'd need something to map the tokens into numbers, and viceversa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c820ccde-c2ee-41ef-b840-41ccca58b550",
      "metadata": {
        "id": "c820ccde-c2ee-41ef-b840-41ccca58b550"
      },
      "outputs": [],
      "source": [
        "# in this case, let's consider a bigram (w1, w2)\n",
        "# assign the w1 to the X vector, and w2 to the y vector, why do we do this?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un conjunto único de palabras para el vocabulario\n",
        "vocab = set(tokens)\n",
        "\n",
        "# Mapear cada palabra a un índice único\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
        "\n",
        "# Convertir los tokens a índices numéricos utilizando el diccionario creado\n",
        "indices = [word_to_idx[word] for word in tokens]\n",
        "\n",
        "# Verificar los primeros índices\n",
        "print(indices[:50])  # Mostrar los primeros 50 índices\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxkFs4dNJ4KL",
        "outputId": "dd80e74b-20c1-48cc-c593-d00b298e0d0e"
      },
      "id": "mxkFs4dNJ4KL",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[675, 513, 639, 598, 15, 901, 769, 666, 1038, 598, 541, 392, 1158, 1266, 1042, 666, 758, 1257, 189, 1016, 1233, 607, 1043, 751, 812, 892, 1163, 339, 541, 586, 525, 344, 625, 554, 765, 666, 1247, 45, 666, 324, 1252, 668, 818, 1163, 378, 1217, 666, 1087, 1133, 666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaax_HHQKEoo",
        "outputId": "c3306ed7-d05a-420a-90cd-0a28696d9047"
      },
      "id": "zaax_HHQKEoo",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1367"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "29c10640-f146-478a-a1a4-d2e747af5ea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c10640-f146-478a-a1a4-d2e747af5ea6",
        "outputId": "9b7b4b8c-0613-428e-edc4-f0bb787bcf17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([675, 513, 639, 598,  15]) tensor([513, 639, 598,  15, 901])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Crear bigramas (w1, w2)\n",
        "bigrams = [(indices[i], indices[i+1]) for i in range(len(indices) - 1)]\n",
        "\n",
        "# Separar los bigramas en X e y\n",
        "X, y = zip(*bigrams)\n",
        "\n",
        "# Convertir X e y a tensores\n",
        "X = torch.tensor(X, dtype=torch.long)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "print(X[:5], y[:5])  # Mostrar los primeros 5 ejemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cfedfd3b-0396-456b-b9f9-f1c07262a721",
      "metadata": {
        "id": "cfedfd3b-0396-456b-b9f9-f1c07262a721"
      },
      "outputs": [],
      "source": [
        "# Don't forget that since we are using torch, our training set vectors should be tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "640c4732-8463-494a-904f-3880975e2273",
      "metadata": {
        "id": "640c4732-8463-494a-904f-3880975e2273"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5984fd00-bdbf-4403-a341-b7ef83138db2",
      "metadata": {
        "id": "5984fd00-bdbf-4403-a341-b7ef83138db2"
      },
      "outputs": [],
      "source": [
        "# Note that our vectors are integers, which can be thought as a categorical variables.\n",
        "# torch provides the one_hot method, that would generate tensors suitable for our nn\n",
        "# make sure that the dtype of your tensor is float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3fb437ef-01ed-4dfd-9d66-5d40f9b6f50c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fb437ef-01ed-4dfd-9d66-5d40f9b6f50c",
        "outputId": "8d3cd0eb-3a8c-4065-d53c-35ba31defee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3602, 1367])\n"
          ]
        }
      ],
      "source": [
        "# Definir la función de one-hot encoding\n",
        "def one_hot_encode(indices, vocab_size):\n",
        "    return torch.eye(vocab_size)[indices]\n",
        "\n",
        "# Tamaño del vocabulario\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Aplicar one-hot encoding a X\n",
        "X_one_hot = one_hot_encode(X, vocab_size)\n",
        "\n",
        "print(X_one_hot.shape)  # Verificar la forma de los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda25114-c6ae-4e07-a743-12e10cd77796",
      "metadata": {
        "id": "cda25114-c6ae-4e07-a743-12e10cd77796"
      },
      "source": [
        "### Network design\n",
        "To start, we are going to have a very simple network. Define a single layer network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # Convertir índices de palabras a vectores de embedding\n",
        "        lstm_out, _ = self.lstm(x)  # Pasar por la LSTM\n",
        "        out = self.fc(lstm_out)  # Pasar por la capa de salida para obtener logits\n",
        "        return torch.softmax(out, dim=-1)  # Aplicar softmax para obtener probabilidades\n"
      ],
      "metadata": {
        "id": "jnqDcKoOPB-A"
      },
      "id": "jnqDcKoOPB-A",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "82bfac7a-e670-4aaf-bf30-5aa8d0ca46e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82bfac7a-e670-4aaf-bf30-5aa8d0ca46e6",
        "outputId": "6928f2ff-01b6-4284-dca8-61c917c267ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/400], Loss: 7.2191\n",
            "Epoch [100/400], Loss: 7.1732\n",
            "Epoch [150/400], Loss: 7.1029\n",
            "Epoch [200/400], Loss: 7.0505\n",
            "Epoch [250/400], Loss: 7.0188\n",
            "Epoch [300/400], Loss: 6.9909\n",
            "Epoch [350/400], Loss: 6.9674\n",
            "Epoch [400/400], Loss: 6.9419\n"
          ]
        }
      ],
      "source": [
        "# How many neurons should our input layer have?\n",
        "# Use as many neurons as the total number of categories (from your one-hot encoded tensors)\n",
        "\n",
        "# Configurar dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Instanciar el modelo y moverlo a GPU\n",
        "model = LSTMModel(vocab_size=vocab_size, embedding_dim=50, hidden_dim=100).to(device)\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Convertir X e y a tensores y moverlos a GPU\n",
        "X_tensor = torch.tensor(indices[:-1], dtype=torch.long).to(device)\n",
        "y_tensor = torch.tensor(indices[1:], dtype=torch.long).to(device)\n",
        "\n",
        "# Entrenamiento\n",
        "epochs = 400\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_tensor.unsqueeze(1))\n",
        "\n",
        "    # Calcular pérdida\n",
        "    loss = criterion(outputs.squeeze(1), y_tensor)\n",
        "\n",
        "    # Backward pass y optimización\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "202a7281-9ebb-4234-b883-2185cb3bcc19",
      "metadata": {
        "id": "202a7281-9ebb-4234-b883-2185cb3bcc19"
      },
      "outputs": [],
      "source": [
        "# Use the softmax as your activation layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "15600485-24e3-4716-92ed-28ac1aa792bd",
      "metadata": {
        "id": "15600485-24e3-4716-92ed-28ac1aa792bd"
      },
      "outputs": [],
      "source": [
        "# Train your network\n",
        "def generar_texto(word, model, word_to_idx, idx_to_word, max_length=50):\n",
        "    model.eval()\n",
        "    g = torch.Generator().manual_seed(67)  # Semilla para reproducibilidad\n",
        "    sentence = [word]\n",
        "    ix = word_to_idx[word]\n",
        "\n",
        "    for _ in range(max_length - 1):\n",
        "        input_seq = torch.tensor([ix], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_seq)\n",
        "\n",
        "        # Muestrear la siguiente palabra basada en las probabilidades del modelo\n",
        "        p = output.squeeze().cpu()\n",
        "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "        word = idx_to_word[ix]\n",
        "        sentence.append(word)\n",
        "\n",
        "        # Romper si la oración termina con un punto\n",
        "        if '.' in word:\n",
        "            break\n",
        "\n",
        "    return ' '.join(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "9grZer1Jwvsc"
      },
      "id": "9grZer1Jwvsc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Test your network with a few words"
      ],
      "metadata": {
        "id": "5jKkCoUdwznl"
      },
      "id": "5jKkCoUdwznl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Probar la generación de texto con algunas palabras iniciales\n",
        "palabras_iniciales = ['aureliano', 'macondo', 'muchos', 'orilla']\n",
        "for i, palabra in enumerate(palabras_iniciales):\n",
        "    oracion_generada = generar_texto(palabra, model, word_to_idx, idx_to_word, max_length=20)\n",
        "    print(f\"{i} {oracion_generada}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEAfAKEIQiVT",
        "outputId": "52f8ba67-dc11-4c9c-af9b-e1d25c34e348"
      },
      "id": "QEAfAKEIQiVT",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 aureliano , y el mundo albahaca.\n",
            "1 macondo , y el mundo albahaca.\n",
            "2 muchos exacto negro , y el mundo comprobado calor.\n",
            "3 orilla de la aldea de la aldea , y el mundo derretida por el mundo peste , y el mundo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la log-verosimilitud negativa para un conjunto de tokens\n",
        "def calcular_nll(tokens, model, word_to_idx):\n",
        "    model.eval()\n",
        "    log_likelihood = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for w1, w2 in zip(tokens, tokens[1:]):\n",
        "        ix1 = word_to_idx[w1]\n",
        "        ix2 = word_to_idx[w2]\n",
        "\n",
        "        input_seq = torch.tensor([ix1], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_seq).squeeze()\n",
        "\n",
        "        pr = output[ix2]\n",
        "        log_likelihood += torch.log(pr).item()\n",
        "        n += 1\n",
        "\n",
        "    return log_likelihood, -log_likelihood, -log_likelihood / n if n > 0 else float('inf')\n",
        "\n",
        "# Calcular NLL para algunas oraciones generadas\n",
        "for i, palabra in enumerate(palabras_iniciales):\n",
        "    oracion_generada = generar_texto(palabra, model, word_to_idx, idx_to_word, max_length=20)\n",
        "    tokens_generados = oracion_generada.split()\n",
        "    log_likelihood, nll, nnll = calcular_nll(tokens_generados, model, word_to_idx)\n",
        "    print(f\"{i} Oración: '{oracion_generada}'\\nLog-Likelihood: {log_likelihood:.4f}, NLL: {nll:.4f}, Normalized NLL: {nnll:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y05FVcTnlb5S",
        "outputId": "1d315cb7-a7c4-4179-ce78-1cf839542333"
      },
      "id": "y05FVcTnlb5S",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Oración: 'aureliano , y el mundo albahaca.'\n",
            "Log-Likelihood: -8.0678, NLL: 8.0678, Normalized NLL: 1.6136\n",
            "\n",
            "1 Oración: 'macondo , y el mundo albahaca.'\n",
            "Log-Likelihood: -8.0496, NLL: 8.0496, Normalized NLL: 1.6099\n",
            "\n",
            "2 Oración: 'muchos exacto negro , y el mundo comprobado calor.'\n",
            "Log-Likelihood: -27.4759, NLL: 27.4759, Normalized NLL: 3.4345\n",
            "\n",
            "3 Oración: 'orilla de la aldea de la aldea , y el mundo derretida por el mundo peste , y el mundo'\n",
            "Log-Likelihood: -21.1965, NLL: 21.1965, Normalized NLL: 1.1156\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d0e838c-3cab-4b6f-b041-1fde6a6d29aa",
      "metadata": {
        "id": "2d0e838c-3cab-4b6f-b041-1fde6a6d29aa"
      },
      "source": [
        "2. What does each value in the tensor represents?\n",
        "3. Why does it make sense to choose that number of neurons in our layer?\n",
        "4. What's the negative likelihood for each example?\n",
        "5. Try generating a few sentences?\n",
        "6. What's the negative likelihood for each sentence?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Cada valor en el tensor de salida del modelo representa la probabilidad predicha de que una palabra específica en el vocabulario sea la siguiente en la secuencia, dado el contexto actual de las palabras anteriores.\n",
        "3. Tiene sentido elegir un número de neuronas en la capa de salida igual al tamaño del vocabulario (vocab_size) porque estamos intentando predecir la próxima palabra en la secuencia entre todas las palabras posibles en nuestro vocabulario\n",
        "4. Una NLL(negative likelihood) más baja indica que el modelo predijo con más confianza y precisión la próxima palabra, mientras que una NLL más alta indica menos confianza y precisión en la predicción.\n",
        "6. En las Oraciones 0 y 1, el modelo parece estar bastante seguro de las palabras generadas, ya que las predicciones son coherentes con lo aprendido durante el entrenamiento. Sin embargo, la repetición de frases como \"y el mundo albahaca\" sugiere que el modelo podría estar atrapado en patrones específicos del entrenamiento.\n",
        "Por otro lado, en la Oración 2, el modelo es menos seguro. Esta secuencia tiene menos coherencia y contiene palabras inesperadas como \"muchos exacto negro\", lo que indica que el modelo no está tan seguro de sus predicciones para esta combinación de palabras.\n",
        "Finalmente, aunque la Oración 3 muestra cierta repetición y puede parecer incoherente (\"y el mundo derretida por el mundo peste\"), el modelo genera estas repeticiones con bastante confianza. Por lo que el modelo ha aprendido ciertos patrones de repetición del texto de entrenamiento, incluso si la oración generada no es completamente coherente desde un punto de vista semántico.\n",
        "\n"
      ],
      "metadata": {
        "id": "LzUQGUx0w-ZI"
      },
      "id": "LzUQGUx0w-ZI"
    },
    {
      "cell_type": "markdown",
      "id": "51e533cf-33b0-4a61-84cb-57c5793893ee",
      "metadata": {
        "id": "51e533cf-33b0-4a61-84cb-57c5793893ee"
      },
      "source": [
        "### Design your own neural network (more layers and different number of neurons)\n",
        "The goal is to get sentences that make more sense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX00it3lbcGC",
        "outputId": "f679077a-fdab-4fbd-eccd-53dc7b8d820a"
      },
      "id": "rX00it3lbcGC",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the text data\n",
        "file_path = '/content/drive/MyDrive/TALLERES NLP /cap1.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    text = file.read().lower()  # Convert to lowercase for normalization\n",
        "\n",
        "# Tokenization\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "# Create a vocabulary dictionary\n",
        "vocab = set(tokens)\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
        "\n",
        "# Convert the tokens to numerical indices\n",
        "indices = [word_to_idx[word] for word in tokens]\n",
        "\n",
        "# Create sequences for training\n",
        "sequence_length = 5  # You can experiment with different lengths\n",
        "X, y = [], []\n",
        "for i in range(len(indices) - sequence_length):\n",
        "    X.append(indices[i:i + sequence_length])\n",
        "    y.append(indices[i + sequence_length])\n",
        "\n",
        "# Convert X and y to PyTorch tensors and move them to the GPU\n",
        "X = torch.tensor(X, dtype=torch.long).to(device)\n",
        "y = torch.tensor(y, dtype=torch.long).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFi9ncRLbgNj",
        "outputId": "72f4f159-7d80-4e8e-fb2e-4817de7a0f54"
      },
      "id": "EFi9ncRLbgNj",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Embedding layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)  # LSTM layers\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)  # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # Convert word indices to embeddings\n",
        "        lstm_out, _ = self.lstm(x)  # LSTM output\n",
        "        out = self.fc(lstm_out[:, -1, :])  # Fully connected layer (predict next word)\n",
        "        return torch.softmax(out, dim=1)  # Softmax for probability distribution\n",
        "\n",
        "# Set hyperparameters\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Instantiate the model and move it to the GPU\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "TMo3U8Y8bjy0"
      },
      "id": "TMo3U8Y8bjy0",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "epochs = 60\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSUcGSRMbl7L",
        "outputId": "ffbfc68c-2592-495e-a8e2-606d2de14175"
      },
      "id": "SSUcGSRMbl7L",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/60], Loss: 7.6624\n",
            "Epoch [10/60], Loss: 7.6624\n",
            "Epoch [15/60], Loss: 7.6611\n",
            "Epoch [20/60], Loss: 7.6417\n",
            "Epoch [25/60], Loss: 7.6060\n",
            "Epoch [30/60], Loss: 7.5978\n",
            "Epoch [35/60], Loss: 7.5962\n",
            "Epoch [40/60], Loss: 7.5956\n",
            "Epoch [45/60], Loss: 7.5952\n",
            "Epoch [50/60], Loss: 7.5951\n",
            "Epoch [55/60], Loss: 7.5949\n",
            "Epoch [60/60], Loss: 7.5948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence(start_word, model, word_to_idx, idx_to_word, max_length=10):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    sentence = [start_word]\n",
        "\n",
        "    # Convert the start word to an index and move to GPU\n",
        "    current_word_idx = torch.tensor([word_to_idx[start_word]], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    for _ in range(max_length - 1):\n",
        "        with torch.no_grad():\n",
        "            # Get the model prediction for the next word\n",
        "            output = model(current_word_idx)\n",
        "\n",
        "            # Get the word index with the highest probability\n",
        "            _, predicted_idx = torch.max(output, 1)\n",
        "            predicted_word = idx_to_word[predicted_idx.item()]\n",
        "\n",
        "            # Add the predicted word to the sentence\n",
        "            sentence.append(predicted_word)\n",
        "\n",
        "            # Update the current word index and move to GPU\n",
        "            current_word_idx = torch.tensor([word_to_idx[predicted_word]], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "# Test sentence generation\n",
        "start_word = 'aureliano'\n",
        "predicted_sentence = generate_sentence(start_word, model, word_to_idx, idx_to_word, max_length=10)\n",
        "print(predicted_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHKb1JzIcylR",
        "outputId": "79996bdb-f5f4-4078-9036-1926b6fddb3f"
      },
      "id": "UHKb1JzIcylR",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aureliano de de de de de de de de de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de palabras iniciales\n",
        "palabras_iniciales = ['aureliano', 'macondo', 'muchos', 'orilla']\n",
        "\n",
        "# Probar la generación de texto con algunas palabras iniciales\n",
        "for i, start_word in enumerate(palabras_iniciales):\n",
        "    predicted_sentence = generate_sentence(start_word, model, word_to_idx, idx_to_word, max_length=5)\n",
        "    print(f\"{i+1}: {predicted_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uRaCejx2x6J",
        "outputId": "2f783d88-af69-4793-b449-39f7a1f0aabb"
      },
      "id": "9uRaCejx2x6J",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: aureliano de de de de\n",
            "2: macondo de de de de\n",
            "3: muchos de de de de\n",
            "4: orilla de de de de\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}